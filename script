# TASK #1: UNDERSTAND THE PROBLEM STATEMENT AND BUSINESS CASE
# TASK #2: IMPORT LIBRARIES AND DATASET
  import pandas as pd
  import numpy as np
  import seaborn as sns
  import matplotlib.pyplot as plt
  import datetime

  sales_train_df = pd.read_csv('/Users/powerbispecialist/Downloads/Data Science for Business Package/3. Sales Department Data/train.csv')
  sales_train_df.head(5)
# almost a million observation 
# 1115 unique stores 
# Note that sales is the target variable (that's what we are trying to predict) 

# Id: transaction ID (combination of Store and date) 
# Store: unique store Id
# Sales: sales/day, this is the target variable 
# Customers: number of customers on a given day
# Open: Boolean to say whether a store is open or closed (0 = closed, 1 = open)
# Promo: describes if store is running a promo on that day or not
# StateHoliday: indicate which state holiday (a = public holiday, b = Easter holiday, c = Christmas, 0 = None)
# SchoolHoliday: indicates if the (Store, Date) was affected by the closure of public schools

#- Data Source: https://www.kaggle.com/c/rossmann-store-sales/data
  sales_train_df.tail(10)
  sales_train_df.info()
# 9 columns in total 
# 8 features, each contains 1017209 data points
# 1 target variable (sales)
  sales_train_df.describe()
# Average sales amount per day = 5773 Euros, minimum sales per day = 0, maximum sales per day = 41551 
# Average number of customers = 633, minimum number of customers = 0, maximum number of customers = 7388
# TASK #2.2: IMPORT STORE INFORMATION DATA
  store_info_df = pd.read_csv('/Users/powerbispecialist/Downloads/Data Science for Business Package/3. Sales Department Data/store.csv')

# StoreType: categorical variable to indicate type of store (a, b, c, d)
# Assortment: describes an assortment level: a = basic, b = extra, c = extended
# CompetitionDistance (meters): distance to closest competitor store
# CompetitionOpenSince [Month/Year]: provides an estimate of the date when competition was open
# Promo2: Promo2 is a continuing and consecutive promotion for some stores (0 = store is not participating, 1 = store is participating)
# Promo2Since [Year/Week]: date when the store started participating in Promo2
# PromoInterval: describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. "Feb,May,Aug,Nov" means each round starts in February, May, August, November of any given year for that store

  store_info_df.head(5)
# Let's do the same for the store_info_df data
# Note that the previous dataframe includes the transactions recorded per day (in millions)
# This dataframe only includes information about the unique 1115 stores that are part of this study 
  store_info_df.info()
  store_info_df.describe()
# TASK #3: EXPLORE DATASET
## #3.1: EXPLORE SALES TRAINING DATA
# Let's see if we have any missing data, luckily we don't!
# sns.heatmap(sales_train_df.isnull(), yticklabels = False, cbar = False, cmap="Blues")
  sns.heatmap(sales_train_df.isnull(), yticklabels = False, cbar = False, cmap="Blues")
# from the look of the graph theres not trace of missing data.
  sales_train_df.hist(bins = 30, figsize = (20,20), color = 'r')
# Average 600 customers per day, maximum is 4500 (note that we can't see the outlier at 7388!)
# Data is equally distibuted across various Days of the week (~150000 observations x 7 day = ~1.1 million observation) 
# Stores are open ~80% of the time
# Data is equally distributed among all stores (no bias)
# Promo #1 was running ~40% of the time 
# Average sales around 5000-6000 Euros
# School holidays are around ~18% of the time
  sales_train_df['Customers'].max()
### Need to check column called open and count the number of stores that where open and closed in the dataset
# Let's see how many stores are open and closed! 
  closed_train_df        = sales_train_df[sales_train_df['Open'] == 0]
  open_train_df          = sales_train_df[sales_train_df['Open'] == 1]
# Count the number of stores that are open and closed
  print("Total =", len(sales_train_df))
  print("Number of closed stores =", len(closed_train_df))
  print("Number of open stores =", len(open_train_df))
# only keep open stores and remove closed stores
  sales_train_df = sales_train_df[sales_train_df['Open'] == 1]
  sales_train_df
### drop the column name open since we have filtered out data and remained with stores thats where open on specificeid days
# Let's drop the open column since it has no meaning now
  sales_train_df.drop(['Open'], axis=1, inplace=True)
  sales_train_df
  sales_train_df.describe()
  # Average sales = 6955 Euros,	average number of customers = 762	(went up)

# TASK #3.2: EXPLORE STORES INFORMATION DATA

# Let's see if we have any missing data in the store information dataframe!
  sns.heatmap(store_info_df.isnull(), yticklabels = False, cbar = False, cmap="Blues")
# Let's take a look at the missing values in the 'CompetitionDistance'
# Only 3 rows are missing 
  store_info_df[store_info_df['CompetitionDistance'].isnull()]
#Let's take a look at the missing values in the 'CompetitionOpenSinceMonth'
# many rows are missing = 354 (almost one third of the 1115 stores)
  store_info_df[store_info_df['CompetitionOpenSinceMonth'].isnull()]
  store_info_df[ store_info_df['Promo2'] == 0]
# It seems like if 'promo2' is zero, 'promo2SinceWeek', 'Promo2SinceYear', and 'PromoInterval' information is set to zero
# There are 354 rows where 'CompetitionOpenSinceYear' and 'CompetitionOpenSinceMonth' is missing
# Let's set these values to zeros 
# simple for loop to go through all the column and fill in empty values to 0
  str_cols = ['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval', 'CompetitionOpenSinceYear', 'CompetitionOpenSinceMonth']
  
  for str in str_cols:
      store_info_df [str].fillna(0, inplace = True)
  sns.heatmap(store_info_df.isnull(), yticklabels = False, cbar = False, cmap="Blues")
# There are 3 rows with 'competitionDistance' values missing, let's fill them up with with average values of the 'CompetitionDistance' column
  store_info_df['CompetitionDistance'].fillna(store_info_df['CompetitionDistance'].mean(), inplace = True)
   sns.heatmap(store_info_df.isnull(), yticklabels = False, cbar = False, cmap="Blues")
  store_info_df.hist(bins = 30, figsize = (20,20), color = 'r')
# half of stores are involved in promo 2
# half of the stores have their competition at a distance of 0-3000m (3 kms away)

# TASK #3.3: EXPLORE MERGED DATASET 

# Let's merge both data frames together based on 'store'
  sales_train_all_df = pd.merge(sales_train_df, store_info_df, how = 'inner', on = 'Store') 
  sales_train_all_df
  sales_train_all_df.to_csv('test.csv', index=False)
# Convert column "Date" to datetime type
  sales_train_all_df['Date'] = pd.to_datetime(sales_train_all_df['Date'])
  
  sales_train_all_df.info()
# customers and promo are positively correlated with the sales 
# Promo2 does not seem to be effective at all 
# Select only numeric columns
numeric_df = sales_train_all_df.select_dtypes(include=['number'])

# Now correlation will work safely
print(numeric_df.corr()['Sales'].sort_values())

correlations = numeric_df.corr()

# 3. Plot heatmap
plt.figure(figsize=(20, 20))
sns.heatmap(correlations, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)

plt.title("Correlation Heatmap", fontsize=18)
plt.show()
# Customers/Prmo2 and sales are strongly correlated 
# Let's separate the year and put it into a separate column 
sales_train_all_df['Year'] = pd.DatetimeIndex(sales_train_all_df['Date']).year
sales_train_all_df
# Let's do the same for the Day and Month
sales_train_all_df['Month'] = pd.DatetimeIndex(sales_train_all_df['Date']).month
sales_train_all_df['Day'] = pd.DatetimeIndex(sales_train_all_df['Date']).day
sales_train_all_df

# VISUALISATION

# Let's take a look at the average sales and number of customers per month 
# 'groupby' works great by grouping all the data that share the same month column, then obtain the mean of the sales column  
# It looks like sales and number of customers peak around christmas timeframe
  axis = sales_train_all_df.groupby('Month')[['Sales']].mean().plot(figsize = (10,5), marker = 'o', color = 'r')
  axis.set_title('Average Sales Per Month')

  plt.figure()
  axis = sales_train_all_df.groupby('Month')[['Customers']].mean().plot(figsize = (10,5), marker = '^', color = 'b')
  axis.set_title('Average Customers Per Month')

# Let's take a look at the sales and customers per day of the month instead
# Minimum number of customers are generally around the 24th of the month 
# Most customers and sales are around 30th and 1st of the month
  ax = sales_train_all_df.groupby('Day')[['Sales']].mean().plot(figsize = (10,5), marker = 'o', color = 'r')
  axis.set_title('Average Sales Per Day')

  plt.figure()
  ax = sales_train_all_df.groupby('Day')[['Customers']].mean().plot(figsize = (10,5), marker = '^', color = 'b')
  axis.set_title('Average Sales Per Day')

# Let's do the same for the day of the week  (note that 7 = Sunday)

axis = sales_train_all_df.groupby('DayOfWeek')[['Sales']].mean().plot(figsize = (10,5), marker = 'o', color = 'r')
axis.set_title('Average Sales Per Day of the Week')

plt.figure()
axis = sales_train_all_df.groupby('DayOfWeek')[['Customers']].mean().plot(figsize = (10,5), marker = '^', color = 'b')
axis.set_title('Average Customers Per Day of the Week')

# Group by Date and StoreType, then take mean of Sales
sales_by_store = sales_train_all_df.groupby(['Date','StoreType'])['Sales'].mean().unstack()

# Plot
fig, ax = plt.subplots(figsize=(20,10))
sales_by_store.plot(ax=ax)
plt.figure(figsize=[15,10])

plt.subplot(211)
sns.barplot(x = 'Promo', y = 'Sales', data = sales_train_all_df)

plt.subplot(212)
sns.barplot(x = 'Promo', y = 'Customers', data = sales_train_all_df)
plt.figure(figsize=[15,10])

plt.subplot(211)
sns.violinplot(x = 'Promo', y = 'Sales', data = sales_train_all_df)

plt.subplot(212)
sns.violinplot(x = 'Promo', y = 'Customers', data = sales_train_all_df)

